{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Approaching Categorical Variables\n\nThis notebook records what I learnt from the AAAMLP book.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import preprocessing\n\npd.set_option('display.max_columns', 100)\n\n# read the data\ndf = pd.read_csv(\"../input/aaamlp/cat_train.csv\")\ndf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-25T07:48:09.787160Z","iopub.execute_input":"2021-08-25T07:48:09.787591Z","iopub.status.idle":"2021-08-25T07:48:12.971276Z","shell.execute_reply.started":"2021-08-25T07:48:09.787554Z","shell.execute_reply":"2021-08-25T07:48:12.970164Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"            id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n0            0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster   \n1            1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl   \n2            2    0.0    1.0    0.0     F     N   Red        NaN  Hamster   \n3            3    NaN    0.0    0.0     F     N   Red     Circle  Hamster   \n4            4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster   \n...        ...    ...    ...    ...   ...   ...   ...        ...      ...   \n599995  599995    0.0    1.0    0.0     T     N   Red    Polygon  Axolotl   \n599996  599996    1.0    0.0    0.0     T     Y  Blue    Polygon      Dog   \n599997  599997    0.0    0.0    0.0     F     Y   Red     Circle  Axolotl   \n599998  599998    1.0    1.0    0.0     F     Y   NaN    Polygon  Axolotl   \n599999  599999    0.0    0.0    0.0     T     N  Blue   Triangle      Dog   \n\n             nom_3     nom_4      nom_5      nom_6      nom_7      nom_8  \\\n0           Russia   Bassoon  de4c57ee2  a64bc7ddf  598080a91  0256c7a4b   \n1              NaN  Theremin  2bb3c3e5c  3a3a936e8  1dddb8473  52ead350c   \n2           Canada   Bassoon  b574c9841  708248125  5ddc9a726  745b909d1   \n3          Finland  Theremin  673bdf1f6  23edb8da3  3a33ef960  bdaa56dd1   \n4       Costa Rica       NaN  777d1ac2c  3a7975e46  bc9cc2a94        NaN   \n...            ...       ...        ...        ...        ...        ...   \n599995       India  Theremin  014770cf0  da5014b01  a7059911d  158183c63   \n599996  Costa Rica      Oboe        NaN  2023ed4ed  83bdea3a5  e9fde8fa8   \n599997      Russia  Theremin  c7dc5d460  5d7d341ac  114b1dbf3  cccbca824   \n599998         NaN     Piano  4d7780407  209e1054e  fba315672  4164322bd   \n599999      Russia  Theremin  17f06e644  f7706ca16  67a8d4ebb        NaN   \n\n            nom_9  ord_0        ord_1        ord_2 ord_3 ord_4 ord_5  day  \\\n0       02e7c8990    3.0  Contributor          Hot     c     U    Pw  6.0   \n1       f37df64af    3.0  Grandmaster         Warm     e     X    pE  7.0   \n2             NaN    3.0          NaN     Freezing     n     P    eN  5.0   \n3       f9d456e57    1.0       Novice     Lava Hot     a     C   NaN  3.0   \n4       c5361037c    3.0  Grandmaster         Cold     h     C    OZ  5.0   \n...           ...    ...          ...          ...   ...   ...   ...  ...   \n599995  015c63324    3.0       Novice     Freezing     a     R    GZ  5.0   \n599996  a02ae6a63    2.0       Novice  Boiling Hot     n     N    sf  NaN   \n599997  40f9610c1    2.0  Contributor     Freezing     n     H    MV  7.0   \n599998  c1a8374a0    1.0       Master         Warm     m     X    Ey  1.0   \n599999  e2aea7784    1.0  Contributor  Boiling Hot     b     O    uI  5.0   \n\n        month  target  \n0         3.0       0  \n1         7.0       0  \n2         9.0       0  \n3         3.0       0  \n4        12.0       0  \n...       ...     ...  \n599995    NaN       0  \n599996    3.0       0  \n599997    5.0       0  \n599998    5.0       0  \n599999    8.0       0  \n\n[600000 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>nom_0</th>\n      <th>nom_1</th>\n      <th>nom_2</th>\n      <th>nom_3</th>\n      <th>nom_4</th>\n      <th>nom_5</th>\n      <th>nom_6</th>\n      <th>nom_7</th>\n      <th>nom_8</th>\n      <th>nom_9</th>\n      <th>ord_0</th>\n      <th>ord_1</th>\n      <th>ord_2</th>\n      <th>ord_3</th>\n      <th>ord_4</th>\n      <th>ord_5</th>\n      <th>day</th>\n      <th>month</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Trapezoid</td>\n      <td>Hamster</td>\n      <td>Russia</td>\n      <td>Bassoon</td>\n      <td>de4c57ee2</td>\n      <td>a64bc7ddf</td>\n      <td>598080a91</td>\n      <td>0256c7a4b</td>\n      <td>02e7c8990</td>\n      <td>3.0</td>\n      <td>Contributor</td>\n      <td>Hot</td>\n      <td>c</td>\n      <td>U</td>\n      <td>Pw</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Red</td>\n      <td>Star</td>\n      <td>Axolotl</td>\n      <td>NaN</td>\n      <td>Theremin</td>\n      <td>2bb3c3e5c</td>\n      <td>3a3a936e8</td>\n      <td>1dddb8473</td>\n      <td>52ead350c</td>\n      <td>f37df64af</td>\n      <td>3.0</td>\n      <td>Grandmaster</td>\n      <td>Warm</td>\n      <td>e</td>\n      <td>X</td>\n      <td>pE</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>NaN</td>\n      <td>Hamster</td>\n      <td>Canada</td>\n      <td>Bassoon</td>\n      <td>b574c9841</td>\n      <td>708248125</td>\n      <td>5ddc9a726</td>\n      <td>745b909d1</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>Freezing</td>\n      <td>n</td>\n      <td>P</td>\n      <td>eN</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Circle</td>\n      <td>Hamster</td>\n      <td>Finland</td>\n      <td>Theremin</td>\n      <td>673bdf1f6</td>\n      <td>23edb8da3</td>\n      <td>3a33ef960</td>\n      <td>bdaa56dd1</td>\n      <td>f9d456e57</td>\n      <td>1.0</td>\n      <td>Novice</td>\n      <td>Lava Hot</td>\n      <td>a</td>\n      <td>C</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>T</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Triangle</td>\n      <td>Hamster</td>\n      <td>Costa Rica</td>\n      <td>NaN</td>\n      <td>777d1ac2c</td>\n      <td>3a7975e46</td>\n      <td>bc9cc2a94</td>\n      <td>NaN</td>\n      <td>c5361037c</td>\n      <td>3.0</td>\n      <td>Grandmaster</td>\n      <td>Cold</td>\n      <td>h</td>\n      <td>C</td>\n      <td>OZ</td>\n      <td>5.0</td>\n      <td>12.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>599995</th>\n      <td>599995</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>T</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Polygon</td>\n      <td>Axolotl</td>\n      <td>India</td>\n      <td>Theremin</td>\n      <td>014770cf0</td>\n      <td>da5014b01</td>\n      <td>a7059911d</td>\n      <td>158183c63</td>\n      <td>015c63324</td>\n      <td>3.0</td>\n      <td>Novice</td>\n      <td>Freezing</td>\n      <td>a</td>\n      <td>R</td>\n      <td>GZ</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>599996</th>\n      <td>599996</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>T</td>\n      <td>Y</td>\n      <td>Blue</td>\n      <td>Polygon</td>\n      <td>Dog</td>\n      <td>Costa Rica</td>\n      <td>Oboe</td>\n      <td>NaN</td>\n      <td>2023ed4ed</td>\n      <td>83bdea3a5</td>\n      <td>e9fde8fa8</td>\n      <td>a02ae6a63</td>\n      <td>2.0</td>\n      <td>Novice</td>\n      <td>Boiling Hot</td>\n      <td>n</td>\n      <td>N</td>\n      <td>sf</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>599997</th>\n      <td>599997</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Red</td>\n      <td>Circle</td>\n      <td>Axolotl</td>\n      <td>Russia</td>\n      <td>Theremin</td>\n      <td>c7dc5d460</td>\n      <td>5d7d341ac</td>\n      <td>114b1dbf3</td>\n      <td>cccbca824</td>\n      <td>40f9610c1</td>\n      <td>2.0</td>\n      <td>Contributor</td>\n      <td>Freezing</td>\n      <td>n</td>\n      <td>H</td>\n      <td>MV</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>599998</th>\n      <td>599998</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>Polygon</td>\n      <td>Axolotl</td>\n      <td>NaN</td>\n      <td>Piano</td>\n      <td>4d7780407</td>\n      <td>209e1054e</td>\n      <td>fba315672</td>\n      <td>4164322bd</td>\n      <td>c1a8374a0</td>\n      <td>1.0</td>\n      <td>Master</td>\n      <td>Warm</td>\n      <td>m</td>\n      <td>X</td>\n      <td>Ey</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>599999</th>\n      <td>599999</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>T</td>\n      <td>N</td>\n      <td>Blue</td>\n      <td>Triangle</td>\n      <td>Dog</td>\n      <td>Russia</td>\n      <td>Theremin</td>\n      <td>17f06e644</td>\n      <td>f7706ca16</td>\n      <td>67a8d4ebb</td>\n      <td>NaN</td>\n      <td>e2aea7784</td>\n      <td>1.0</td>\n      <td>Contributor</td>\n      <td>Boiling Hot</td>\n      <td>b</td>\n      <td>O</td>\n      <td>uI</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>600000 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1(a) Convert categories to numbers using dictionary map","metadata":{}},{"cell_type":"code","source":"df.ord_2.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:12.972859Z","iopub.execute_input":"2021-08-25T07:48:12.973148Z","iopub.status.idle":"2021-08-25T07:48:13.136229Z","shell.execute_reply.started":"2021-08-25T07:48:12.973120Z","shell.execute_reply":"2021-08-25T07:48:13.134531Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Freezing       142726\nWarm           124239\nCold            97822\nBoiling Hot     84790\nHot             67508\nLava Hot        64840\nNaN             18075\nName: ord_2, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# convert categories to numbers using dictionary map.\nmapping = {\n    \"Freezing\": 0,\n    \"Warm\": 1,\n    \"Cold\": 2,\n    \"Boiling Hot\": 3,\n    \"Hot\": 4,\n    \"Lava Hot\": 5\n}\n\ndf.loc[:, \"ord_2\"] = df.ord_2.map(mapping)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:13.138713Z","iopub.execute_input":"2021-08-25T07:48:13.139182Z","iopub.status.idle":"2021-08-25T07:48:13.298336Z","shell.execute_reply.started":"2021-08-25T07:48:13.139134Z","shell.execute_reply":"2021-08-25T07:48:13.297356Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df.ord_2.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:13.299821Z","iopub.execute_input":"2021-08-25T07:48:13.300125Z","iopub.status.idle":"2021-08-25T07:48:13.320538Z","shell.execute_reply.started":"2021-08-25T07:48:13.300096Z","shell.execute_reply":"2021-08-25T07:48:13.319551Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.0    142726\n1.0    124239\n2.0     97822\n3.0     84790\n4.0     67508\n5.0     64840\nNaN     18075\nName: ord_2, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1(b) Convert categories to numbers using LabelEncoder\n\nWe can use this directly in many tree-based models:\n- Decision trees\n- Random forest\n- Extra Trees\n- Or any kind of boosted trees model (XGBoost, GBM, LightGBM)\n\n**This type of encoding cannot be used in linear models, support vector machines or neural networks as they expect data to be normalized (or standardized).**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/aaamlp/cat_train.csv\")\ndf.ord_2.value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:13.321840Z","iopub.execute_input":"2021-08-25T07:48:13.322121Z","iopub.status.idle":"2021-08-25T07:48:16.294595Z","shell.execute_reply.started":"2021-08-25T07:48:13.322095Z","shell.execute_reply":"2021-08-25T07:48:16.293511Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"Freezing       142726\nWarm           124239\nCold            97822\nBoiling Hot     84790\nHot             67508\nLava Hot        64840\nNaN             18075\nName: ord_2, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\") # Fill NaN values in ord_2 column.\nlbl_enc = preprocessing.LabelEncoder()       # LabelEncoder does not handle NaN values.\n\n# fit label encoder and transform values on ord_2 column\n# P.S: do not use this directly. fit first, then transform\ndf.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:16.296062Z","iopub.execute_input":"2021-08-25T07:48:16.296516Z","iopub.status.idle":"2021-08-25T07:48:16.712619Z","shell.execute_reply.started":"2021-08-25T07:48:16.296474Z","shell.execute_reply":"2021-08-25T07:48:16.711537Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df.ord_2.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:16.713821Z","iopub.execute_input":"2021-08-25T07:48:16.714123Z","iopub.status.idle":"2021-08-25T07:48:16.726830Z","shell.execute_reply.started":"2021-08-25T07:48:16.714094Z","shell.execute_reply":"2021-08-25T07:48:16.725787Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"2    142726\n6    124239\n1     97822\n0     84790\n3     67508\n4     64840\n5     18075\nName: ord_2, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. One-Hot Encoding","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/aaamlp/cat_train.csv\")\ndf.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\") # Fill NaN values in ord_2 column.\nohe = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False) # Dense array\npd.DataFrame(ohe.fit_transform(df[\"ord_2\"].values.reshape(-1, 1)))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:16.729112Z","iopub.execute_input":"2021-08-25T07:48:16.729441Z","iopub.status.idle":"2021-08-25T07:48:19.926597Z","shell.execute_reply.started":"2021-08-25T07:48:16.729411Z","shell.execute_reply":"2021-08-25T07:48:19.925555Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"          0    1    2    3    4    5    6\n0       0.0  0.0  0.0  1.0  0.0  0.0  0.0\n1       0.0  0.0  0.0  0.0  0.0  0.0  1.0\n2       0.0  0.0  1.0  0.0  0.0  0.0  0.0\n3       0.0  0.0  0.0  0.0  1.0  0.0  0.0\n4       0.0  1.0  0.0  0.0  0.0  0.0  0.0\n...     ...  ...  ...  ...  ...  ...  ...\n599995  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n599996  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n599997  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n599998  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n599999  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n\n[600000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>599995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>599996</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>599997</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>599998</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>599999</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>600000 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/aaamlp/cat_train.csv\")\ndf.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\") # Fill NaN values in ord_2 column.\nohe = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=True) # Sparse array\npd.DataFrame(ohe.fit_transform(df[\"ord_2\"].values.reshape(-1, 1)))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:48:19.928335Z","iopub.execute_input":"2021-08-25T07:48:19.928754Z","iopub.status.idle":"2021-08-25T07:49:04.723857Z","shell.execute_reply.started":"2021-08-25T07:48:19.928702Z","shell.execute_reply":"2021-08-25T07:49:04.722852Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                    0\n0         (0, 3)\\t1.0\n1         (0, 6)\\t1.0\n2         (0, 2)\\t1.0\n3         (0, 4)\\t1.0\n4         (0, 1)\\t1.0\n...               ...\n599995    (0, 2)\\t1.0\n599996    (0, 0)\\t1.0\n599997    (0, 2)\\t1.0\n599998    (0, 6)\\t1.0\n599999    (0, 0)\\t1.0\n\n[600000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0, 3)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0, 6)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(0, 2)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(0, 4)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(0, 1)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>599995</th>\n      <td>(0, 2)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>599996</th>\n      <td>(0, 0)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>599997</th>\n      <td>(0, 2)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>599998</th>\n      <td>(0, 6)\\t1.0</td>\n    </tr>\n    <tr>\n      <th>599999</th>\n      <td>(0, 0)\\t1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>600000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3. Converting categorical variables to numerical variables","metadata":{}},{"cell_type":"code","source":"df.groupby([\"ord_2\"])[\"id\"].count()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:49:04.725156Z","iopub.execute_input":"2021-08-25T07:49:04.725529Z","iopub.status.idle":"2021-08-25T07:49:04.793884Z","shell.execute_reply.started":"2021-08-25T07:49:04.725497Z","shell.execute_reply":"2021-08-25T07:49:04.792728Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"ord_2\nBoiling Hot     84790\nCold            97822\nFreezing       142726\nHot             67508\nLava Hot        64840\nNONE            18075\nWarm           124239\nName: id, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.groupby([\"ord_2\"])[\"id\"].transform(\"count\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:49:04.795416Z","iopub.execute_input":"2021-08-25T07:49:04.795849Z","iopub.status.idle":"2021-08-25T07:49:04.863472Z","shell.execute_reply.started":"2021-08-25T07:49:04.795790Z","shell.execute_reply":"2021-08-25T07:49:04.862466Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"0          67508\n1         124239\n2         142726\n3          64840\n4          97822\n           ...  \n599995    142726\n599996     84790\n599997    142726\n599998    124239\n599999     84790\nName: id, Length: 600000, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.groupby([\"ord_1\", \"ord_2\"])[\"id\"].count().reset_index(name=\"count\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:49:04.864619Z","iopub.execute_input":"2021-08-25T07:49:04.864899Z","iopub.status.idle":"2021-08-25T07:49:05.046878Z","shell.execute_reply.started":"2021-08-25T07:49:04.864871Z","shell.execute_reply":"2021-08-25T07:49:05.045884Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"          ord_1        ord_2  count\n0   Contributor  Boiling Hot  15634\n1   Contributor         Cold  17734\n2   Contributor     Freezing  26082\n3   Contributor          Hot  12428\n4   Contributor     Lava Hot  11919\n5   Contributor         NONE   3250\n6   Contributor         Warm  22774\n7        Expert  Boiling Hot  19477\n8        Expert         Cold  22956\n9        Expert     Freezing  33249\n10       Expert          Hot  15792\n11       Expert     Lava Hot  15078\n12       Expert         NONE   4225\n13       Expert         Warm  28900\n14  Grandmaster  Boiling Hot  13623\n15  Grandmaster         Cold  15464\n16  Grandmaster     Freezing  22818\n17  Grandmaster          Hot  10805\n18  Grandmaster     Lava Hot  10363\n19  Grandmaster         NONE   2894\n20  Grandmaster         Warm  19899\n21       Master  Boiling Hot  10800\n22       Master         Cold  12364\n23       Master     Freezing  18035\n24       Master          Hot   8594\n25       Master     Lava Hot   8209\n26       Master         NONE   2262\n27       Master         Warm  15734\n28       Novice  Boiling Hot  22718\n29       Novice         Cold  26271\n30       Novice     Freezing  38233\n31       Novice          Hot  17850\n32       Novice     Lava Hot  17373\n33       Novice         NONE   4889\n34       Novice         Warm  33263","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ord_1</th>\n      <th>ord_2</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Contributor</td>\n      <td>Boiling Hot</td>\n      <td>15634</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Contributor</td>\n      <td>Cold</td>\n      <td>17734</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Contributor</td>\n      <td>Freezing</td>\n      <td>26082</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Contributor</td>\n      <td>Hot</td>\n      <td>12428</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Contributor</td>\n      <td>Lava Hot</td>\n      <td>11919</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Contributor</td>\n      <td>NONE</td>\n      <td>3250</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Contributor</td>\n      <td>Warm</td>\n      <td>22774</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Expert</td>\n      <td>Boiling Hot</td>\n      <td>19477</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Expert</td>\n      <td>Cold</td>\n      <td>22956</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Expert</td>\n      <td>Freezing</td>\n      <td>33249</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Expert</td>\n      <td>Hot</td>\n      <td>15792</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Expert</td>\n      <td>Lava Hot</td>\n      <td>15078</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Expert</td>\n      <td>NONE</td>\n      <td>4225</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Expert</td>\n      <td>Warm</td>\n      <td>28900</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Grandmaster</td>\n      <td>Boiling Hot</td>\n      <td>13623</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Grandmaster</td>\n      <td>Cold</td>\n      <td>15464</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Grandmaster</td>\n      <td>Freezing</td>\n      <td>22818</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Grandmaster</td>\n      <td>Hot</td>\n      <td>10805</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Grandmaster</td>\n      <td>Lava Hot</td>\n      <td>10363</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Grandmaster</td>\n      <td>NONE</td>\n      <td>2894</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Grandmaster</td>\n      <td>Warm</td>\n      <td>19899</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Master</td>\n      <td>Boiling Hot</td>\n      <td>10800</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Master</td>\n      <td>Cold</td>\n      <td>12364</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Master</td>\n      <td>Freezing</td>\n      <td>18035</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Master</td>\n      <td>Hot</td>\n      <td>8594</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Master</td>\n      <td>Lava Hot</td>\n      <td>8209</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Master</td>\n      <td>NONE</td>\n      <td>2262</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Master</td>\n      <td>Warm</td>\n      <td>15734</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Novice</td>\n      <td>Boiling Hot</td>\n      <td>22718</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Novice</td>\n      <td>Cold</td>\n      <td>26271</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Novice</td>\n      <td>Freezing</td>\n      <td>38233</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Novice</td>\n      <td>Hot</td>\n      <td>17850</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Novice</td>\n      <td>Lava Hot</td>\n      <td>17373</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Novice</td>\n      <td>NONE</td>\n      <td>4889</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Novice</td>\n      <td>Warm</td>\n      <td>33263</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 4. Create new features from these categorical variables","metadata":{}},{"cell_type":"code","source":"df[\"new_feature\"] = (df.ord_1.astype(str) + \"_\" + df.ord_2.astype(str))\ndf[\"new_feature\"] ","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:49:05.048247Z","iopub.execute_input":"2021-08-25T07:49:05.048577Z","iopub.status.idle":"2021-08-25T07:49:05.282676Z","shell.execute_reply.started":"2021-08-25T07:49:05.048547Z","shell.execute_reply":"2021-08-25T07:49:05.281755Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"0                 Contributor_Hot\n1                Grandmaster_Warm\n2                    nan_Freezing\n3                 Novice_Lava Hot\n4                Grandmaster_Cold\n                   ...           \n599995            Novice_Freezing\n599996         Novice_Boiling Hot\n599997       Contributor_Freezing\n599998                Master_Warm\n599999    Contributor_Boiling Hot\nName: new_feature, Length: 600000, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# 5. If you have a fixed test set, you can add your test data to training to know about the categories in a given feature.\n\nIf you design your cross-validation in such a way that it replicates the prediction process when you run your model on test data, then it’s never going to overfit.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import preprocessing\n\n# Read training and test data.\ntrain = pd.read_csv(\"../input/aaamlp/cat_train.csv\")\ntest = pd.read_csv(\"../input/aaamlp/cat_test.csv\")\n\n# Create a fake target column for test data since this column doesn't exist.\ntest.loc[:, \"target\"] = -1\n\n# Concatenate both training and test data.\ndata = pd.concat([train, test]).reset_index(drop=True)\n\n# Make a list of features we are interested in (id and target is something we should not encode).\nfeatures = [x for x in train.columns if x not in [\"id\", \"target\"]]\n\n# Loop over the features list.\nfor feat in features:\n    # Create a new instance of LabelEncoder for each feature\n    lbl_enc = preprocessing.LabelEncoder()    \n    \"\"\"\n    Note the trick here. Since its categorical data, we fillna with a string\n    and convert all the data to string type.\n    So, no matter its int or float, its converted to string.\n    int/float but categorical!!!\n    \"\"\"  \n    temp_col = data[feat].fillna(\"NONE\").astype(str).values\n    # we can use fit_transform here as we do not have any extra test data that we need to\n    # transform on separately.\n    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n    \n# split the training and test data again.\ntrain = data[data.target != -1].reset_index(drop=True)\ntest = data[data.target == -1].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:49:05.283929Z","iopub.execute_input":"2021-08-25T07:49:05.284198Z","iopub.status.idle":"2021-08-25T07:49:26.051219Z","shell.execute_reply.started":"2021-08-25T07:49:05.284172Z","shell.execute_reply":"2021-08-25T07:49:26.050276Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# 6. Rare categories","metadata":{}},{"cell_type":"code","source":"df[\"ord_4\"] = df.ord_4.fillna(\"NONE\")\ndf[\"ord_4\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:56:06.841766Z","iopub.execute_input":"2021-08-25T07:56:06.842116Z","iopub.status.idle":"2021-08-25T07:56:07.046502Z","shell.execute_reply.started":"2021-08-25T07:56:06.842087Z","shell.execute_reply":"2021-08-25T07:56:07.045573Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"N       39978\nP       37890\nY       36657\nA       36633\nR       33045\nU       32897\nM       32504\nX       32347\nC       32112\nH       31189\nQ       30145\nT       29723\nO       25610\nB       25212\nE       21871\nK       21676\nI       19805\nNONE    17930\nD       17284\nF       16721\nW        8268\nZ        5790\nS        4595\nG        3404\nV        3107\nJ        1950\nL        1657\nName: ord_4, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.loc[\n    df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000, \n    \"ord_4\"\n] = \"RARE\"\n\ndf.ord_4.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T07:56:42.079163Z","iopub.execute_input":"2021-08-25T07:56:42.079574Z","iopub.status.idle":"2021-08-25T07:56:42.617519Z","shell.execute_reply.started":"2021-08-25T07:56:42.079538Z","shell.execute_reply":"2021-08-25T07:56:42.616453Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"N       39978\nP       37890\nY       36657\nA       36633\nR       33045\nU       32897\nM       32504\nX       32347\nC       32112\nH       31189\nQ       30145\nT       29723\nO       25610\nB       25212\nE       21871\nK       21676\nI       19805\nNONE    17930\nD       17284\nF       16721\nW        8268\nZ        5790\nS        4595\nRARE     3607\nG        3404\nV        3107\nName: ord_4, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Logistic regression with OHE","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\ndef run(fold):\n    # load the full training data with folds.\n    df = pd.read_csv(\"../input/aaamlp/cat_train_folds.csv\")\n\n    # all columns are features except id, target and kfold columns.\n    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n    \n    # fill all NaN values with NONE.    \n    for col in features:\n        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n        \n    # get training & validation data using folds.\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    # initialize OneHotEncoder from scikit-learn\n    ohe = preprocessing.OneHotEncoder()\n    \n    # fit ohe on training + validation features\n    full_data = pd.concat([df_train[features], df_valid[features]], axis=0)\n    ohe.fit(full_data[features])\n    \n    # transform training data\n    x_train = ohe.transform(df_train[features])\n    \n    # transform validation data\n    x_valid = ohe.transform(df_valid[features])\n    \n    # initialize Logistic Regression model\n    model = linear_model.LogisticRegression()\n\n    # fit model on training data (ohe)\n    model.fit(x_train, df_train.target.values)\n    \n    # predict on validation data.\n    # we need the probability values as we are calculating AUC.\n    # we will use the probability of 1s.\n    valid_preds = model.predict_proba(x_valid)[:, 1]\n    \n    # get roc auc score\n    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)    \n    print(auc)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T08:09:01.576917Z","iopub.execute_input":"2021-08-25T08:09:01.577282Z","iopub.status.idle":"2021-08-25T08:09:01.587427Z","shell.execute_reply.started":"2021-08-25T08:09:01.577247Z","shell.execute_reply":"2021-08-25T08:09:01.586342Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    run(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest with Label Encoding","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\ndef run(fold):\n    # load the full training data with folds\n    df = pd.read_csv(\"../input/aaamlp/cat_train_folds.csv\")\n    \n    # all columns are features except id, target and kfold columns\n    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n    \n    # fill all NaN values with NONE\n    for col in features:\n        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n        \n    # now its time to label encode the features\n    for col in features:        \n        lbl = preprocessing.LabelEncoder()      # initialize LabelEncoder for each feature column.        \n        lbl.fit(df[col])                        # fit label encoder on all data.        \n        df.loc[:, col] = lbl.transform(df[col]) # transform all the data\n        \n    # get training & validation data using folds\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    # get training & validation data\n    x_train = df_train[features].values\n    x_valid = df_valid[features].values\n    \n    # initialize random forest model\n    model = ensemble.RandomForestClassifier(n_jobs = -1)\n    \n    # fit model on training data (ohe)\n    model.fit(x_train, df_train.target.values)\n    \n    # predict on validation data\n    # we need the probability values as we are calculating AUC\n    # we will use the probability of 1s\n    valid_preds = model.predict_proba(x_valid)[:, 1]\n    \n    # get roc auc score\n    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n    print(f\"Fold = {fold}, AUC = {auc}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T08:15:23.423425Z","iopub.execute_input":"2021-08-25T08:15:23.424043Z","iopub.status.idle":"2021-08-25T08:15:23.572571Z","shell.execute_reply.started":"2021-08-25T08:15:23.424000Z","shell.execute_reply":"2021-08-25T08:15:23.571173Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    for fold_ in range(5):\n        run(fold_)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T08:15:26.596799Z","iopub.execute_input":"2021-08-25T08:15:26.597207Z","iopub.status.idle":"2021-08-25T08:21:55.775876Z","shell.execute_reply.started":"2021-08-25T08:15:26.597164Z","shell.execute_reply":"2021-08-25T08:21:55.774790Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Fold = 0, AUC = 0.7168783658859279\nFold = 1, AUC = 0.715838531629464\nFold = 2, AUC = 0.7164466090008996\nFold = 3, AUC = 0.715129421431247\nFold = 4, AUC = 0.7166935259054454\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Random Forest with Decomposition\n\nWe one-hot encode the full data and then fit TruncatedSVD from scikit-learn on sparse matrix with training + validation data. In this way, we reduce the high dimensional sparse matrix to 120 features and then fit random forest classifier.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy import sparse\nfrom sklearn import decomposition\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\ndef run(fold):\n    # load the full training data with folds\n    df = pd.read_csv(\"../input/aaamlp/cat_train_folds.csv\")\n    \n    # all columns are features except id, target and kfold columns\n    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n    \n    # fill all NaN values with NONE    \n    for col in features:\n        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n        \n    # get training & validation data using folds\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    # initialize OneHotEncoder from scikit-learn\n    ohe = preprocessing.OneHotEncoder()\n    \n    # fit ohe on training + validation features\n    full_data = pd.concat([df_train[features], df_valid[features]], axis=0)\n    ohe.fit(full_data[features])\n    \n    # transform training data\n    x_train = ohe.transform(df_train[features])\n    \n    # transform validation data\n    x_valid = ohe.transform(df_valid[features])\n    \n    # initialize Truncated SVD. We are reducing the data to 120 components.\n    svd = decomposition.TruncatedSVD(n_components=120)\n    \n    # fit svd on full sparse training data\n    full_sparse = sparse.vstack((x_train, x_valid))\n    svd.fit(full_sparse)\n    \n    # transform sparse training data\n    x_train = svd.transform(x_train)\n    # transform sparse validation data\n    x_valid = svd.transform(x_valid)\n    \n    # initialize random forest model\n    model = ensemble.RandomForestClassifier(n_jobs=-1)\n    \n    # fit model on training data (ohe)\n    model.fit(x_train, df_train.target.values)\n    \n    # predict on validation data\n    # we need the probability values as we are calculating AUC\n    # we will use the probability of 1s\n    valid_preds = model.predict_proba(x_valid)[:, 1]\n    # get roc auc score\n    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n    # print auc\n    print(f\"Fold = {fold}, AUC = {auc}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T08:23:11.520820Z","iopub.execute_input":"2021-08-25T08:23:11.521178Z","iopub.status.idle":"2021-08-25T08:23:11.533879Z","shell.execute_reply.started":"2021-08-25T08:23:11.521148Z","shell.execute_reply":"2021-08-25T08:23:11.532794Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    for fold_ in range(5):\n        run(fold_)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T08:23:14.800507Z","iopub.execute_input":"2021-08-25T08:23:14.800873Z","iopub.status.idle":"2021-08-25T09:09:08.804398Z","shell.execute_reply.started":"2021-08-25T08:23:14.800840Z","shell.execute_reply":"2021-08-25T09:09:08.803143Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Fold = 0, AUC = 0.7068733733177661\nFold = 1, AUC = 0.7062245490824105\nFold = 2, AUC = 0.709164591352216\nFold = 3, AUC = 0.7050484363896786\nFold = 4, AUC = 0.7063249849954278\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# XGBoost with Label Encoding","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport xgboost as xgb\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\ndef run(fold):\n    # load the full training data with folds\n    df = pd.read_csv(\"../input/aaamlp/cat_train_folds.csv\")\n    \n    # all columns are features except id, target and kfold columns\n    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n    \n    # fill all NaN values with NONE    \n    for col in features:\n        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n        \n    # now it’s time to label encode the features\n    for col in features:        \n        lbl = preprocessing.LabelEncoder()      # initialize LabelEncoder for each feature column.        \n        lbl.fit(df[col])                        # fit label encoder on all data.        \n        df.loc[:, col] = lbl.transform(df[col]) # transform all the data.\n    \n    # get training data using folds\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    # get validation data using folds\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    # get training data\n    x_train = df_train[features].values\n    # get validation data\n    x_valid = df_valid[features].values\n    \n    # initialize xgboost model\n    model = xgb.XGBClassifier(n_jobs=-1, max_depth=7, n_estimators=200)\n    \n    # fit model on training data (ohe)\n    model.fit(x_train, df_train.target.values)\n    \n    # predict on validation data\n    # we need the probability values as we are calculating AUC\n    # we will use the probability of 1s\n    valid_preds = model.predict_proba(x_valid)[:, 1]\n    # get roc auc score\n    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)    \n    print(f\"Fold = {fold}, AUC = {auc}\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T09:09:08.806063Z","iopub.execute_input":"2021-08-25T09:09:08.806746Z","iopub.status.idle":"2021-08-25T09:09:08.953039Z","shell.execute_reply.started":"2021-08-25T09:09:08.806693Z","shell.execute_reply":"2021-08-25T09:09:08.951927Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    for fold_ in range(5):\n        run(fold_)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T09:09:08.955291Z","iopub.execute_input":"2021-08-25T09:09:08.955606Z","iopub.status.idle":"2021-08-25T09:17:11.530814Z","shell.execute_reply.started":"2021-08-25T09:09:08.955578Z","shell.execute_reply":"2021-08-25T09:17:11.529728Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[09:09:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nFold = 0, AUC = 0.7619427726331363\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[09:11:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nFold = 1, AUC = 0.7594102460900842\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[09:12:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nFold = 2, AUC = 0.7625341621789485\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[09:14:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nFold = 3, AUC = 0.76130659574446\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[09:15:50] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nFold = 4, AUC = 0.7630714164013852\n","output_type":"stream"}]}]}